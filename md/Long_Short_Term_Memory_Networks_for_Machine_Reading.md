## Long_Short_Term_Memory_Networks_for_Machine_Reading
### Questions
- TODO


### Key Concepts
- Memory compression
- Intra-attention


### Reference Repo
- [SNLI-attention][1]

[1]:https://github.com/cheng6076/SNLI-attention